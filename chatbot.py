import os
import numpy as np
import faiss
import pandas as pd
import streamlit as st
import nltk
from nltk.tokenize import sent_tokenize
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from openai import OpenAI
import subprocess
import sys

# Certifique-se de ter baixado os pacotes necess√°rios
nltk.download('punkt')
nltk.download('punkt_tab')

# Fun√ß√£o para instalar as depend√™ncias
def install_requirements():
    if 'dependencies_installed' in st.session_state and st.session_state.dependencies_installed:
        return  # Depend√™ncias j√° instaladas, n√£o instala novamente

    requirements_file = "requirements.txt"
    if os.path.exists(requirements_file):
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", requirements_file])
            print("Depend√™ncias instaladas com sucesso!")
            st.session_state.dependencies_installed = True  # Marca como instalado
        except subprocess.CalledProcessError as e:
            print(f"Erro ao instalar depend√™ncias: {e}")
    else:
        print(f"Arquivo {requirements_file} n√£o encontrado!")

# Configura√ß√£o da chave de API
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)

# Fun√ß√£o para pr√©-processar o texto
def preprocess_text(text):
    sentences = sent_tokenize(text)
    return sentences

# Fun√ß√£o para dividir o texto em chunks
def split_text(text):
    text_splitter = CharacterTextSplitter(
        separator='\n',
        chunk_size=2000,
        chunk_overlap=400
    )
    texts = text_splitter.split_text(text)
    return texts

# Fun√ß√£o para criar embeddings e indexa√ß√£o com FAISS
def create_embeddings(texts):
    embeddings = OpenAIEmbeddings()
    doc_embeddings = embeddings.embed_documents(texts)
    dimension = len(doc_embeddings[0])
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(doc_embeddings))
    return embeddings, index

# Fun√ß√£o para buscar os documentos relevantes
def search_docs(query, embeddings, index, texts, k=3):
    query_embedding = embeddings.embed_query(query)
    distances, indices = index.search(np.array([query_embedding]), k)
    results = [texts[i] for i in indices[0]]
    return results

# Fun√ß√£o para gerar a resposta usando o modelo atualizado
def generate_answer(messages, embeddings, index, texts):
    question = messages[-1]["content"]
    context = search_docs(question, embeddings, index, texts)
    context_str = "\n\n".join(context)

    api_messages = [
        {"role": "system", "content": "Voc√™ √© um assistente especializado no Vestibular da Unicamp 2025. Responda √†s perguntas dos usu√°rios usando apenas as informa√ß√µes do edital oficial fornecido. Seja preciso e direto. Se n√£o encontrar a resposta no contexto, indique que n√£o possui essa informa√ß√£o."},
    ]

    previous_messages = messages[-3:] if len(messages) >= 3 else messages
    for msg in previous_messages[:-1]:
        api_messages.append(msg)

    last_user_message = messages[-1]
    last_user_message_with_context = {
        "role": last_user_message["role"],
        "content": f"Contexto:\n{context_str}\n\nPergunta:\n{last_user_message['content']}"
    }
    api_messages.append(last_user_message_with_context)

    chat_completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=api_messages,
        max_tokens=400,
        temperature=0.3
    )
    answer = chat_completion.choices[0].message.content.strip()
    return answer

# Fun√ß√£o principal do aplicativo Streamlit
def main():
    # Chamar a fun√ß√£o no in√≠cio do script
    install_requirements()

    # Configura√ß√£o da p√°gina
    st.set_page_config(page_title="Chatbot Vestibular Unicamp 2025", page_icon="üéì", layout="wide")

    # Adicionar estilo customizado
    st.markdown("""
        <style>
            .stChatMessage {
                font-size: 1.1em;
            }
            .user {
                background-color: #DCF8C6;
            }
            .assistant {
                background-color: #F1F0F0;
            }
            footer {visibility: hidden;}
        </style>
        """, unsafe_allow_html=True)

    # Criar a barra lateral
    with st.sidebar:
        st.image("UNICAMP.png", use_container_width=True)
        st.markdown("## Sobre")
        st.write("Este chatbot foi desenvolvido para ajudar candidatos a esclarecer d√∫vidas sobre o Vestibular da Unicamp 2025.")
        st.markdown("---")
        st.markdown("### Desenvolvido por")
        st.write("Augusto Zolet")
        st.write("[LinkedIn](https://www.linkedin.com) | [GitHub](https://github.com)")

    st.title("üéì Chatbot Vestibular Unicamp 2025")
    st.write("Bem-vindo ao chatbot que responde suas d√∫vidas sobre o Vestibular da Unicamp 2025! Digite sua pergunta abaixo e aguarde a resposta.")

    # Barra de progresso durante o processamento
    if 'texts' not in st.session_state:
        with st.spinner('Processando o edital, por favor aguarde...'):
            with open('Normas.txt', 'r', encoding='utf-8') as file:
                edital_text = file.read()
            sentences = preprocess_text(edital_text)
            texts = split_text(edital_text)
            embeddings, index = create_embeddings(texts)
            st.session_state.texts = texts
            st.session_state.embeddings = embeddings
            st.session_state.index = index
    else:
        texts = st.session_state.texts
        embeddings = st.session_state.embeddings
        index = st.session_state.index

    if 'messages' not in st.session_state:
        st.session_state.messages = []

    # Exibir mensagens anteriores
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Entrada de chat
    question = st.chat_input("Digite sua pergunta sobre o vestibular:")

    if question:
        # Adicionar a mensagem do usu√°rio ao estado da sess√£o
        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(f"**Voc√™:** {question}")

        # Gerar a resposta do assistente
        with st.spinner('Gerando resposta...'):
            try:
                answer = generate_answer(st.session_state.messages, embeddings, index, texts)
                # Adicionar a resposta do assistente ao estado da sess√£o
                st.session_state.messages.append({"role": "assistant", "content": answer})
                with st.chat_message("assistant"):
                    st.markdown(f"**Chatbot:** {answer}")
            except Exception as e:
                st.error(f"Ocorreu um erro: {e}")

if __name__ == '__main__':
    main()
